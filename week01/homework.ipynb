{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework â„–1\n",
    "\n",
    "    In this homework you will need to implement the following stuff:\n",
    "        1) Discrete Fourier Transform\n",
    "        2) Fast Fourier Transform\n",
    "        3) Compare by performance\n",
    "        4) Short-time Fourier Transform based on (2) and hann window function\n",
    "        5) MelScale\n",
    "        6) Digit classification based on you melspectrograms\n",
    "        \n",
    "    Note:\n",
    "        You should test your implementation with torchaudio functions\n",
    "        (e.g. torch.allclose(torchaudio.transforms.Spectrogram.__call__, your_function))\n",
    "\n",
    "### Main rules\n",
    "    1) All operations must be implemented with pytorch (don't use numpy)\n",
    "    2) Everything should support batch input\n",
    "    3) No cycles, only matrix multiplications\n",
    "    4) Clean and clear code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Fourier Transform (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file = 'audio.wav'\n",
    "wav, sr = torchaudio.load(wav_file)\n",
    "\n",
    "torch.allclose(\n",
    "    torch.stft,\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Fourier Transform (3pts)\n",
    "\n",
    "    A common task for machine learning engineer is to take an paper and implement it.\n",
    "    So, just do it!\n",
    "[Tap on me](http://www.robots.ox.ac.uk/~sjrob/Teaching/SP/l7.pdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A comparison of the performance (1e-7 pts)\n",
    "    Do pretty images :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short-time Fourier Transform (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Use torch.hann_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MelScale (2 pts)\n",
    "\n",
    "[Tap on me](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit classification (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) Download data from google drive: https://drive.google.com/file/d/1ouSOru91p-ZJCyI6E8cGh7N0r3vffi06/view?usp=sharing\n",
    "    \n",
    "    2) Split data in 80/20 proportion. Please note that both the train and the test\n",
    "    must contain all types of digits and all speakers, so carefully split the data.\n",
    "    \n",
    "    3) The AudioMNIST dataset1 consists of 30000 audio recordings (9.5 hours) \n",
    "    of spoken digits (0-9) in English with 50 repetitions per digit for each of the 60 different speakers.\n",
    "    \n",
    "    4) Build a classificator of spoken digits. You can use any neural network architecture you like.\n",
    "        The minimum required quality of classificator will be announced.\n",
    "    \n",
    "    5) Each wavfile has the following format: digit_speackerid_wavid.wav\n",
    "        For example, 6_01_47.wav:\n",
    "            6 -- the number 6 is spoken\n",
    "            01 -- the number is spoken by 1 speaker\n",
    "            47 -- id of wavfile        \n",
    "\n",
    "    Bonus:\n",
    "        If you implement a good model or use some augmentation (or something else),\n",
    "        you can expect to obtain bonuses of up to 3 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
